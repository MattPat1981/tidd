{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Tsunami-related Total Electron Content Anomalies in the Ionosphere with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import fastprogress\n",
    "from hyperdash import monitor_cell, Experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish an Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with a model name, then autostart\n",
    "exp = Experiment(\"Tsunami-related sTEC d/dt Anomaly Detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking device number\n",
    "assert torch.cuda.is_available()\n",
    "index_device = torch.cuda.current_device()\n",
    "device_name = exp.param(\"device_name\", torch.cuda.get_device_name(index_device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data path \n",
    "data_path_train = \"/home/vconstan/projects/sTEC-d-dt-Anomaly-Detection/data/image_based_balanced/hawaii/train\"\n",
    "data_path_train = exp.param(\"data_path_train\", data_path_train)\n",
    "# data_path = \"/u/scratch/s/stecproj/image_data/image_based/hawaii/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size \n",
    "batch_size = 256\n",
    "batch_size = exp.param(\"batch_size\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data \n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    data_path_train, \n",
    "    item_tfms=Resize(224),\n",
    "    valid_pct=0.2,\n",
    "    bs=batch_size, #512, changed to 256 since my(Hamlin) GPU ran out of memory\n",
    "    ds_tfms=aug_transforms(do_flip=True, flip_vert=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 9 sample images with correspond to our two labels in the dataset - normal and anomalous \n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.dataset = dls.dataset.new(shuffle=False, sampler=ImbalancedDatasetSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the learner \n",
    "architecture = resnet34\n",
    "\n",
    "learn = cnn_learner(\n",
    "    dls, # data\n",
    "    architecture, # architecture \n",
    "    metrics=[error_rate, accuracy], # metrics\n",
    "    pretrained=False, # whether or not to use transfer learning\n",
    "    normalize=True, # this function adds a Normalization transform to the dls\n",
    "#     callback_fns=[]\n",
    ")\n",
    "\n",
    "architecture = exp.param(\"architecture\", architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, manually set the learning rate (automatic LR finders left for future work)\n",
    "lr = 0.00001 # 0.00001 best result so far but not a given \n",
    "lr = exp.param(\"learning_rate\", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel GPUs! Seems to work with squeezenet but not with resnet models (have not tried densenet, VGG or others)\n",
    "parallel_gpus = False\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     parallel_gpus = True\n",
    "#     learn.model = nn.DataParallel(learn.model)\n",
    "parallel_gpus = exp.param(\"parallel_gpus\", parallel_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a threshold for calculating coverage\n",
    "coverage_threshold = exp.param(\"coverage_threshold\", 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_scores(cm: np.ndarray):\n",
    "    \"\"\"\n",
    "    Returns a tuple of classification metrics according to\n",
    "    the anomalous class as True Positive\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm)/np.sum(cm)\n",
    "    total_anon = np.sum(cm[0]) if np.sum(cm[0]) > 0 else 1\n",
    "    pred_anon = np.sum(cm[:, 0]) if np.sum(cm[:, 0]) > 0 else 1\n",
    "    precision = cm[0, 0] / total_anon\n",
    "    recall = cm[0, 0] / pred_anon\n",
    "    denom = (precision + recall) if (precision + recall) > 0 else 1\n",
    "    F1 = 2 * precision * recall / denom\n",
    "    return accuracy, precision, recall, F1\n",
    "\n",
    "def calculating_coverage(predictions: torch.Tensor, targets: torch.Tensor, threshold: float):\n",
    "    \"\"\"\n",
    "    Given a N-sized validation set,\n",
    "    predictions is an N x 2 tensor since this is a binary classification problem\n",
    "    targes is an N x 1 tensor where each targets[i] is the correct class\n",
    "    \n",
    "    returns 2 tuple of all coverages of each class\n",
    "    \"\"\"\n",
    "    anomalous = np.where(targets == 0)\n",
    "    normal = np.where(targets == 1)\n",
    "    normal_predictions = predictions[normal, 1]\n",
    "    anomalous_predictions = predictions[anomalous, 0]\n",
    "    anom_coverage = np.average(anomalous_predictions > threshold)\n",
    "    normal_coverage = np.average(normal_predictions > threshold)\n",
    "    return anom_coverage, normal_coverage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max number of epochs\n",
    "epochs_max = exp.param(\"epochs_max\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperdash API key: HaWsBsqUzqosfHQPw7XMSwl9l1gnGiUr05uydAzqxfo=\n",
    "\n",
    "# set the parameters \n",
    "# TODO: size training\n",
    "# TODO: size validation \n",
    "# TODO: size holdout \n",
    "# TODO: holdout channels (ground station, satellite combinations)\n",
    "# TODO: pretrained \n",
    "# TODO: normalize \n",
    "# TODO: callbacks \n",
    "\n",
    "# train the model \n",
    "learn.fit(\n",
    "    epochs_max, \n",
    "    lr=lr,\n",
    "    cbs=[\n",
    "        ShowGraphCallback(),\n",
    "        CSVLogger(),\n",
    "#         ParamScheduler(sched),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='valid_loss', \n",
    "            min_delta=0.001, \n",
    "            patience=5\n",
    "        ),\n",
    "        EarlyStoppingCallback(\n",
    "            monitor=\"valid_loss\",\n",
    "            patience=10,\n",
    "            min_delta=0.00001\n",
    "        ),\n",
    "        SaveModelCallback()\n",
    "    ]\n",
    ") \n",
    "\n",
    "# TODO: total training time \n",
    "# TODO: train loss, valid loss, error rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve from model training\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(4,4), dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpret results from test set\n",
    "interp = ClassificationInterpretation.from_learner(learn) \n",
    "cm = interp.confusion_matrix()\n",
    "\n",
    "results = confusion_matrix_scores(cm)\n",
    "accuracy = exp.metric(\"accuracy\", results[0])\n",
    "precision = exp.metric(\"precision\", results[1])\n",
    "recall = exp.metric(\"recall\", results[2])\n",
    "F1_score = exp.metric(\"F1 Score\", results[3])\n",
    "\n",
    "\n",
    "# coverage calculation\n",
    "predictions, targets = learn.get_preds() #by default uses validation set\n",
    "anom_cov, normal_cov = calculating_coverage(predictions, targets, coverage_threshold)\n",
    "anomaly_cov = exp.metric(\"anomaly coverage\", anom_cov)\n",
    "normal_cov = exp.metric(\"normal coverage\", normal_cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"../models/model.pkl\") # TODO: clean up export path and where model saves history, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Load in Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(\"../models/model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for the validation set of data \n",
    "data_path_validation = \"/home/vconstan/projects/sTEC-d-dt-Anomaly-Detection/data/image_based_balanced/hawaii/validation\"\n",
    "# data_path_validation = exp.param(\"data_path_validation\", data_path_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "def group_consecutives(vals, step=1):\n",
    "    \"\"\"Return list of consecutive lists of numbers from vals (number list).\n",
    "    https://stackoverflow.com/questions/7352684/how-to-find-the-groups-of-consecutive-elements-in-a-numpy-array\n",
    "    \"\"\"\n",
    "    run = []\n",
    "    result = [run]\n",
    "    expect = None\n",
    "    for v in vals:\n",
    "        if (v == expect) or (expect is None):\n",
    "            run.append(v)\n",
    "        else:\n",
    "            run = [v]\n",
    "            result.append(run)\n",
    "        expect = v + step\n",
    "    return result\n",
    "\n",
    "\n",
    "# TODO: add typing for leerner\n",
    "def real_world_simulation(data_path: str, learner, verbose: bool = False) -> None: \n",
    "    \n",
    "    # define the annotations we use later for visualization and metrics reporting \n",
    "    sod_annotations = {\n",
    "        \"G04\": 31400,\n",
    "        \"G07\": 31160,\n",
    "        \"G08\": 31900,\n",
    "        \"G10\": 29900,\n",
    "        \"G20\": 31150\n",
    "    }\n",
    "    \n",
    "    # TODO: fix unintended printing from fastai\n",
    "    with learner.no_bar():\n",
    "                \n",
    "        # disable logging \n",
    "        learner.no_logging()\n",
    "\n",
    "        # first get all of the directories at the specified path \n",
    "        directories = os.listdir(data_path) # TODO: add validation to only pull directories not files \n",
    "\n",
    "        tp_tot = 0\n",
    "        fn_tot = 1\n",
    "        fp_tot = 0\n",
    "\n",
    "        # now run predictions on each example in the data set\n",
    "        for d in tqdm(directories): \n",
    "\n",
    "            try:\n",
    "\n",
    "                sat_name = d.split(\"__\")[1]\n",
    "                ground_station_name = d.split(\"__\")[0]\n",
    "                pass_id = ground_station_name + \"__\" + sat_name\n",
    "\n",
    "                # get all of the image files from the day of the earthquake \n",
    "                # TODO: use all of the days not just the day of the earthquake for validation (depends on timing)\n",
    "\n",
    "                # get all of the image paths in that directory for the day of the earthquake\n",
    "                image_files = [f for f in natsort.natsorted(os.listdir(data_path + \"/\" + d + \"/unlabeled\")) if \".jpg\" in f and \"302\" in f.split(\"_\")[0]]\n",
    "\n",
    "                # make predictions for all of the images from that day \n",
    "                # these were converted previously. In real world would need real-time conversion from float to image and \n",
    "                # then to classification \n",
    "                # for each image (window), predict and store the classification \n",
    "                classification = list()\n",
    "                classification_confidence = list()\n",
    "                windows = list()\n",
    "                window_start = 0\n",
    "                window_end = 60\n",
    "                for img in image_files: \n",
    "\n",
    "                    try:\n",
    "\n",
    "                        # load in the image and predict the classification \n",
    "                        prediction = learner.predict(data_path + \"/\" + d + \"/unlabeled/\" + img)\n",
    "\n",
    "                        # store the classification and the window range \n",
    "                        classification.append(prediction[0])\n",
    "                        classification_confidence.append(np.max(prediction[2].cpu().detach().numpy()))\n",
    "\n",
    "                        windows.append([window_start, window_end])\n",
    "                        window_start += 1\n",
    "                        window_end += 1    \n",
    "                    except:\n",
    "                        print(\"Error encountered when predicting!\")\n",
    "\n",
    "                classification_bool = [0 if x == \"normal\" else 1 for x in classification]\n",
    "\n",
    "\n",
    "                # store the classification result in a time-indexed array that is T minutes long by W windows tall \n",
    "                # the number of minutes T is the number of windows plus the window size, or window_end\n",
    "                period_classification_df = pd.DataFrame(\n",
    "                    index=list(range(0, len(image_files))),\n",
    "                    columns=list(range(0, window_end - 1))\n",
    "                ).astype(float)\n",
    "\n",
    "                # note that this matrix can be used to classify anomalies with different weighting schemes\n",
    "                # this is left for future work. We take the naive approach and say that any time index \n",
    "                # identified as anomaly is one \n",
    "\n",
    "                # and fill \n",
    "                index = 0\n",
    "                for c, cc, w in zip(classification, classification_confidence, windows):\n",
    "                    if c == \"normal\":\n",
    "                        val = 0\n",
    "                    else:\n",
    "                        val = 1\n",
    "                    period_classification_df.iloc[index, w[0]:w[1]] = val\n",
    "                    index += 1\n",
    "\n",
    "\n",
    "        #         if verbose is True: \n",
    "\n",
    "        #             # TODO: create a function for this and refactor a bit here\n",
    "        #             # show this as a heatmap to explain concept \n",
    "        #             with sns.axes_style(\"darkgrid\"):\n",
    "        #                 plt.figure(figsize=(8, 10))\n",
    "        #                 # mask = np.isnan(period_classification_df.astype(float).values)\n",
    "        #                 # mask[np.triu_indices_from(mask)] = True\n",
    "        #                 # ax = sns.heatmap(period_classification_df.astype(float), mask=mask)\n",
    "        #                 ax = sns.heatmap(period_classification_df, cmap=\"viridis\", cbar=True, cbar_kws={\"shrink\": .65})\n",
    "        #                 plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # now we need to load in the original data (float data) that contains the second of day \n",
    "                # and other data needed for visualization and metrics reporting \n",
    "                try:\n",
    "                    sat = \"../data/hawaii/2012/302/\" + ground_station_name + \"3020.12o_\" + sat_name + \".txt\"\n",
    "\n",
    "                    f = open(sat, 'r')\n",
    "                    line1 = f.readline()\n",
    "\n",
    "                except:\n",
    "                    print(\"Error reading float data!\")\n",
    "\n",
    "                line1 = line1.replace('#', '').replace(\"dsTEC/dt [TECU/s]\", \"dsTEC/dt\").replace(\"elev\", \"ele\")\n",
    "                rename_cols = line1.split()\n",
    "                rename_cols.remove(\"sod\")\n",
    "                new_cols = list()\n",
    "\n",
    "                # rename the columns\n",
    "                for rn_col in rename_cols:\n",
    "                    new_col = pass_id + \"_\" + rn_col\n",
    "                    if rn_col == \"dsTEC/dt\":\n",
    "                        new_col = pass_id\n",
    "                    new_cols.append(new_col)\n",
    "                new_cols = [\"sod\"] + new_cols\n",
    "\n",
    "\n",
    "                df = pd.read_table(\n",
    "                    sat,\n",
    "                    index_col='sod',\n",
    "                    sep=\"\\t\\t| \",\n",
    "                    names=new_cols,\n",
    "                    engine=\"python\",\n",
    "                    skiprows=1\n",
    "                )\n",
    "\n",
    "                new_cols.remove('sod')\n",
    "\n",
    "                sod = df.index\n",
    "                timestamps = list()\n",
    "                date = datetime(2012, 1, 1) + timedelta(302 - 1)\n",
    "\n",
    "                for s in sod:\n",
    "\n",
    "                    # hours, minutes, seconds\n",
    "                    hours = int(s // 3600)\n",
    "                    minutes = int((s % 3600) // 60)\n",
    "                    seconds = int((s % 60))\n",
    "\n",
    "                    # create a datetime object and append to the list\n",
    "                    date_time = datetime(date.year, date.month, date.day, hours, minutes, seconds)\n",
    "                    timestamps.append(date_time)\n",
    "\n",
    "\n",
    "                df[\"timestamp\"] = timestamps\n",
    "                new_cols.append(\"timestamp\")\n",
    "\n",
    "                # now that we have read in the data, do some formatting \n",
    "                df = df[new_cols].reset_index()\n",
    "                df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "                df.index = df[\"timestamp\"]\n",
    "                df = df.resample(\"1Min\").mean()\n",
    "\n",
    "\n",
    "                #  # TODO: okay so now let's generate some metrics\n",
    "                # like the code that generates the \"events\", we will determine the predicted \n",
    "                # sequence of anomalies and record whether or not they are true positives \n",
    "\n",
    "                # For simplicity, we do not make scoring adjustments based on\n",
    "                # how early an anomaly was detected or the distance between false\n",
    "                # positives and labeled regions\n",
    "\n",
    "                ground_truth = [\n",
    "                    sod_annotations[sat_name],\n",
    "                    sod_annotations[sat_name] + (30 * 60) # 30 minutes \n",
    "                ]\n",
    "\n",
    "                df_ranges = df.copy().reset_index()\n",
    "                ground_truth_sequence = df_ranges[(df_ranges[\"sod\"] >= ground_truth[0]) & (df_ranges[\"sod\"] <= ground_truth[1])].index.values\n",
    "\n",
    "                anom_idx = np.where(np.array(classification_bool) == 1)\n",
    "                anom_sequences = group_consecutives(list(anom_idx[0]))\n",
    "\n",
    "                # A true positive is recorded if any portion of a predicted sequence of anomalies falls within any\n",
    "                # true labeled sequence. Only one true positive is recorded\n",
    "                # even if portions of multiple predicted sequences fall within\n",
    "                # a labeled sequence.\n",
    "\n",
    "                # If no predicted sequences overlap with a positively labeled\n",
    "                # sequence, a false negative is recorded for the labeled sequence\n",
    "\n",
    "                # For all predicted sequences that do not overlap a labeled\n",
    "                # anomalous region, a false positive is recorded\n",
    "\n",
    "                tp = 0\n",
    "                fn = 1\n",
    "                fp = 0\n",
    "\n",
    "                # TODO: Hamlin please double check me on this \n",
    "                # NOTE: current code assumes one anomalous sequence \n",
    "\n",
    "                for anom_seq in anom_sequences: \n",
    "                    intersection = list(set(ground_truth_sequence) & set(anom_seq)) \n",
    "                    if len(intersection) > 0:\n",
    "                        tp = 1 \n",
    "                        fn = 0\n",
    "                    else:\n",
    "                        fp += 1\n",
    "\n",
    "                tp_tot += tp\n",
    "                fn_tot += fn\n",
    "                fp_tot += fp\n",
    "\n",
    "                # identify continuous periods as we do when we generate the images and prep the data \n",
    "                events = np.split(df, np.where(np.isnan(df))[0])\n",
    "                events = [ev[~np.isnan(ev)] for ev in events if not isinstance(ev, np.ndarray)]\n",
    "                events = [ev.dropna() for ev in events if not ev.empty and ev.shape[0] > 100]\n",
    "\n",
    "                # generate the normalized events in case we need them \n",
    "                normalized_events = list()\n",
    "                for ev in events: \n",
    "\n",
    "                    # for each column in the data, rescale -1 to 1 \n",
    "                    col_data = list()\n",
    "                    for col in ev.columns.values:\n",
    "\n",
    "                        normalized_data = minmax_scale(\n",
    "                                    ev[col].dropna(), \n",
    "                                    feature_range=(-1, 1)\n",
    "                                )\n",
    "                        col_data.append(normalized_data)\n",
    "\n",
    "                    df_period = pd.DataFrame(np.array(col_data).T, columns=list(ev.columns.values) )\n",
    "                    df_period[\"timestamp\"] = ev[col].index\n",
    "                    df_period.index = df_period[\"timestamp\"]\n",
    "                    df_period = df_period.drop(columns=[\"timestamp\"])\n",
    "\n",
    "                    # convert to seconds of the day for later annotation \n",
    "                    df_period[\"sod\"] = (df_period.index.hour*60+df_period.index.minute)*60 + df_period.index.second\n",
    "\n",
    "                    normalized_events.append(df_period)\n",
    "\n",
    "                # make pretty plots! \n",
    "                if verbose: \n",
    "\n",
    "                    fig, axs = plt.subplots(3, sharex=False, sharey=False, figsize=(12, 4))\n",
    "                    fig.tight_layout()\n",
    "                    fig.suptitle('Day of Earthquake Predictions by Second of Day (SoD) for ' + pass_id + \"\\n\")\n",
    "\n",
    "                    gs = plt.GridSpec(3, 1, height_ratios=[3, 1, 1]) \n",
    "\n",
    "                    axs[0] = plt.subplot(gs[0])\n",
    "                    sns.lineplot(data=events[0].iloc[59:, :], x=\"sod\", y=pass_id, ax=axs[0])\n",
    "                    axs[0].set(yticklabels=[]) \n",
    "                    axs[0].axvline(x=sod_annotations[sat_name], linestyle=\"dotted\") # start \n",
    "                    axs[0].axvline(x=sod_annotations[sat_name] + (30 * 60), linestyle=\"dotted\") # approx end - 30 minutes later \n",
    "                    #TODo: do we need to revisit data generation / labeling? \n",
    "                    axs[0].margins(x=0)\n",
    "                    axs[0].set_xlabel(\"\")\n",
    "\n",
    "                    axs[1] = plt.subplot(gs[1])\n",
    "                    sns.heatmap(np.array([classification_bool]), cbar=False, cmap=\"plasma\", xticklabels=False, yticklabels=False, ax=axs[1])\n",
    "                    axs[1].set_xlabel(\"Prediction (yellow is anomaly)\") \n",
    "\n",
    "                    axs[2] = plt.subplot(gs[2])\n",
    "                    sns.heatmap(np.array([classification_confidence]), cbar=False, cmap=\"plasma_r\", xticklabels=False, yticklabels=False, ax=axs[2]) # .replace(0, np.nan)\n",
    "                    axs[2].set_xlabel(\"Prediction Confidence (yellow is worse)\") \n",
    "\n",
    "\n",
    "                    plt.subplots_adjust(left=0.125,\n",
    "                                        bottom=0.1, \n",
    "                                        right=0.9, \n",
    "                                        top=0.9, \n",
    "                                        wspace=0.2, \n",
    "                                        hspace=0.5)\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "            except:\n",
    "                print(\"ERROR: \", d)\n",
    "                continue\n",
    "\n",
    "        print(tp_tot, fp_tot, fn_tot)\n",
    "                \n",
    "        try:\n",
    "            precision = tp_tot / (tp_tot + fp_tot)\n",
    "        except ZeroDivisionError:\n",
    "            precision = 0.\n",
    "            \n",
    "        try:\n",
    "            recall = tp_tot / (tp_tot + fn_tot)\n",
    "        except ZeroDivisionError:\n",
    "            recall = 0.\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "        precision = exp.metric(\"validation_precision\", precision)\n",
    "        recall = exp.metric(\"validation_recall\", recall)\n",
    "        f1_score = exp.metric(\"validation_f1_score\", f1_score)\n",
    "        \n",
    "        print(precision, recall, f1_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_world_simulation(\n",
    "    data_path=data_path_validation,\n",
    "    learner=learn,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate sequence labels so we can see if the sequences overlap \n",
    "# TODO: follow the experiment setup we used in the telemanbom paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is older code that exists above and ought to be refactored and made nice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress. For now, building out base functionality with a single set of data in the validation set \n",
    "test_path = data_path_validation + \"/kaep__G20/unlabeled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the image paths in that directory for the day of the earthquake\n",
    "image_files = [f for f in natsort.natsorted(os.listdir(test_path)) if \".jpg\" in f and \"302\" in f.split(\"_\")[0]]\n",
    "image_files[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each image (window), predict and store the classification \n",
    "\n",
    "classification = list()\n",
    "classification_confidence = list()\n",
    "windows = list()\n",
    "\n",
    "\n",
    "window_start = 0\n",
    "window_end = 60\n",
    "for img in tqdm(image_files): \n",
    "    \n",
    "    # load in the image and predict the classification \n",
    "    prediction = learn.predict(test_path + img)\n",
    "\n",
    "    # store the classification and the window range \n",
    "    classification.append(prediction[0])\n",
    "    classification_confidence.append(np.max(prediction[2].cpu().detach().numpy()))\n",
    "    \n",
    "    windows.append([window_start, window_end])\n",
    "    window_start += 1\n",
    "    window_end += 1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the classification result in a time-indexed array that is T minutes long by W windows tall \n",
    "# the number of minutes T is the number of windows plus the window size, or window_end\n",
    "period_classification_df = pd.DataFrame(\n",
    "    index=list(range(0, len(image_files))),\n",
    "    columns=list(range(0, window_end - 1))\n",
    ").astype(float)\n",
    "\n",
    "# and fill \n",
    "index = 0\n",
    "for c, cc, w in zip(classification, classification_confidence, windows):\n",
    "    \n",
    "    if c == \"normal\":\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    \n",
    "    period_classification_df.iloc[index, w[0]:w[1]] = val\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "period_classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_name = \"G20\"\n",
    "ground_station_name = \"kaep\"\n",
    "pass_id = ground_station_name + \"__\" + sat_name\n",
    "\n",
    "sat = \"../data/hawaii/2012/302/\" + ground_station_name + \"3020.12o_\" + sat_name + \".txt\"\n",
    "\n",
    "f = open(sat, 'r')\n",
    "line1 = f.readline()\n",
    "line1 = line1.replace('#', '').replace(\"dsTEC/dt [TECU/s]\", \"dsTEC/dt\").replace(\"elev\", \"ele\")\n",
    "rename_cols = line1.split()\n",
    "rename_cols.remove(\"sod\")\n",
    "new_cols = list()\n",
    "\n",
    "# rename the columns\n",
    "for rn_col in rename_cols:\n",
    "    new_col = pass_id + \"_\" + rn_col\n",
    "    if rn_col == \"dsTEC/dt\":\n",
    "        new_col = pass_id\n",
    "    new_cols.append(new_col)\n",
    "new_cols = [\"sod\"] + new_cols\n",
    "\n",
    "\n",
    "df = pd.read_table(\n",
    "    sat,\n",
    "    index_col='sod',\n",
    "    sep=\"\\t\\t| \",\n",
    "    names=new_cols,\n",
    "    engine=\"python\",\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "new_cols.remove('sod')\n",
    "\n",
    "sod = df.index\n",
    "timestamps = list()\n",
    "date = datetime(2012, 1, 1) + timedelta(302 - 1)\n",
    "\n",
    "for s in sod:\n",
    "\n",
    "    # hours, minutes, seconds\n",
    "    hours = int(s // 3600)\n",
    "    minutes = int((s % 3600) // 60)\n",
    "    seconds = int((s % 60))\n",
    "\n",
    "    # create a datetime object and append to the list\n",
    "    date_time = datetime(date.year, date.month, date.day, hours, minutes, seconds)\n",
    "    timestamps.append(date_time)\n",
    "\n",
    "\n",
    "df[\"timestamp\"] = timestamps\n",
    "new_cols.append(\"timestamp\")\n",
    "    \n",
    "df[new_cols].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[new_cols].reset_index()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df.index = df[\"timestamp\"]\n",
    "df = df.resample(\"1Min\").mean()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = np.split(df, np.where(np.isnan(df))[0])\n",
    "    \n",
    "events = [ev[~np.isnan(ev)] for ev in events if not isinstance(ev, np.ndarray)]\n",
    "    \n",
    "events = [ev.dropna() for ev in events if not ev.empty and ev.shape[0] > 100]\n",
    "\n",
    "normalized_events = list()\n",
    "for ev in events: \n",
    "\n",
    "    # for each column in the data, rescale -1 to 1 \n",
    "    col_data = list()\n",
    "    for col in ev.columns.values:\n",
    "\n",
    "        normalized_data = minmax_scale(\n",
    "                    ev[col].dropna(), \n",
    "                    feature_range=(-1, 1)\n",
    "                )\n",
    "        col_data.append(normalized_data)\n",
    "\n",
    "    df_period = pd.DataFrame(np.array(col_data).T, columns=list(ev.columns.values) )\n",
    "    df_period[\"timestamp\"] = ev[col].index\n",
    "    df_period.index = df_period[\"timestamp\"]\n",
    "    df_period = df_period.drop(columns=[\"timestamp\"])\n",
    "\n",
    "    # convert to seconds of the day for later annotation \n",
    "    df_period[\"sod\"] = (df_period.index.hour*60+df_period.index.minute)*60 + df_period.index.second\n",
    "\n",
    "    normalized_events.append(df_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to simulate the real world, we'll get the latest classification result for the newest time index \n",
    "# this means that the first indication is used for the overall classification \n",
    "# however, some slack could be built into the system taking a majority vote over the last N minutes. \n",
    "# introduces lag but could reduce false positives\n",
    "# system will be built this way from the beginning. \n",
    "\n",
    "# normalized_events[0]\n",
    "# events[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume the starts are the same... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod_annotations = {\n",
    "    \"G04\": 31400,\n",
    "    \"G07\": 31160,\n",
    "    \"G08\": 31900,\n",
    "    \"G10\": 29900,\n",
    "    \"G20\": 31150\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, sharex=False, sharey=False, figsize=(12, 4))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.suptitle('Day of Earthquake Predictions by Second of Day (SoD) for ' + pass_id + \"\\n\")\n",
    "\n",
    "gs = plt.GridSpec(3, 1, height_ratios=[3, 1, 1]) \n",
    "\n",
    "\n",
    "axs[0] = plt.subplot(gs[0])\n",
    "sns.lineplot(data=events[0].iloc[59:, :], x=\"sod\", y=pass_id, ax=axs[0])\n",
    "axs[0].set(yticklabels=[]) \n",
    "axs[0].axvline(x=sod_annotations[sat_name], linestyle=\"dotted\") # start \n",
    "axs[0].axvline(x=sod_annotations[sat_name] + (30 * 60), linestyle=\"dotted\") # approx end - 30 minutes later \n",
    "#TODo: do we need to revisit data generation / labeling? \n",
    "axs[0].margins(x=0)\n",
    "axs[0].set_xlabel(\"\")\n",
    "\n",
    "axs[1] = plt.subplot(gs[1])\n",
    "classification_bool = [0 if x == \"normal\" else 1 for x in classification]\n",
    "sns.heatmap(np.array([classification_bool]), cbar=False, cmap=\"plasma\", xticklabels=False, yticklabels=False, ax=axs[1])\n",
    "axs[1].set_xlabel(\"Prediction (yellow is anomaly)\") \n",
    "\n",
    "axs[2] = plt.subplot(gs[2])\n",
    "sns.heatmap(np.array([classification_confidence]), cbar=False, cmap=\"plasma_r\", xticklabels=False, yticklabels=False, ax=axs[2]) # .replace(0, np.nan)\n",
    "axs[2].set_xlabel(\"Prediction Confidence (yellow is worse)\") \n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0.125,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.2, \n",
    "                    hspace=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[0].iloc[59:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_classification_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 1))\n",
    "# ax = sns.heatmap(np.array([classification_confidence]), cbar=False, cmap=\"plasma_r\", xticklabels=False, yticklabels=False)\n",
    "# ax.set_xlabel(\"Prediction Confidence (yellow is worse)\") \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 1))\n",
    "# classification_bool = [0 if x == \"normal\" else 1 for x in classification]\n",
    "# ax = sns.heatmap(np.array([classification_bool]), cbar=False, cmap=\"plasma\", xticklabels=False, yticklabels=False)\n",
    "# ax.set_xlabel(\"Prediction (yellow is anomaly)\") \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 3))\n",
    "# ax = sns.lineplot(data=events[0], x=\"sod\", y=\"alep__G07\")\n",
    "# ax.set(yticklabels=[]) \n",
    "# ax.axvline(x=sod_annotations[\"G07\"], linestyle=\"dotted\") # start \n",
    "# ax.axvline(x=sod_annotations[\"G07\"] + (30 * 60), linestyle=\"dotted\") # approx end - 30 minutes later \n",
    "# #TODO: do we need to revisit data generation / labeling? \n",
    "# ax.margins(x=0)\n",
    "# ax.set_xlabel(\"Second of Day (with anomaly start and approximate end times)\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: holdout recall, precision, accuracy, f-score,  as well \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the experiment \n",
    "exp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH work\n",
    "### To be deleted when requesting merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cache and variables \n",
    "a = learn.get_preds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.argmax(a[0], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.dls[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = learn.get_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True, act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = interp.confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trace(z)/np.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(z[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.loaders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = interp.confusion_matrix()\n",
    "accuracy = np.trace(cm)/np.sum(cm)\n",
    "total_anon = np.sum(cm[0]) if np.sum(cm[0]) > 0 else 1\n",
    "pred_anon = np.sum(cm[:, 0]) if np.sum(cm[:, 0]) > 0 else 1\n",
    "precision = cm[0, 0] / total_anon\n",
    "recall = cm[0, 0] / pred_anon\n",
    "denom = (precision + recall) if (precision + recall) > 0 else 1\n",
    "F1 = 2 * precision * recall / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.dls[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = learn.get_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True, act=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normal[4460])\n",
    "len(normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(anomalies[29])\n",
    "PIL.Image.open(anomalies[29])\n",
    "PIL.Image.open(normal[4460])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = get_image_files(data_path + \"pat2__G08/labeled/anomalous/\")\n",
    "normal = get_image_files(data_path + \"pat2__G08/labeled/normal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t = learn.get_preds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(t) == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, targets = learn.get_preds()\n",
    "anomalous = np.where(targets == 0)\n",
    "normal = np.where(targets == 1)\n",
    "normal_predictions = predictions[normal, 1]\n",
    "anomalous_predictions = predictions[anomalous, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(normal_predictions > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = calculating_coverage(predictions, targets, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
