{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing the Pipeline\n",
    "\n",
    "In this notebook, we explore how long it takes to go from having the sTEC data in float format to getting a predictio for that window (the machine learning part of the pipeline). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "import fastprogress\n",
    "from hyperdash import monitor_cell, Experiment\n",
    "import matplotlib.pyplot as plt\n",
    "import natsort\n",
    "import numpy as np\n",
    "import os \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# # load any resources fr4om this library \n",
    "from src import data\n",
    "\n",
    "from pyts.image import GramianAngularField # not currently working in env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = list(range(290, 305))\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2012\n",
    "location = \"hawaii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 290---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [00:30<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 291---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1654/1654 [00:30<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 292---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1646/1646 [00:27<00:00, 60.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n",
      "\n",
      "--- 293---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1649 [00:00<01:12, 22.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1649/1649 [00:29<00:00, 56.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1655 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 294---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [00:30<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1648 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 295---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648/1648 [00:31<00:00, 53.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1655 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 296---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1655/1655 [00:29<00:00, 55.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1647 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 297---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1647/1647 [00:29<00:00, 55.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1657 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 298---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1657/1657 [00:29<00:00, 55.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1656 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 299---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1656/1656 [00:30<00:00, 55.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1595 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 300---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1595/1595 [00:30<00:00, 51.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1596 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 301---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596/1596 [00:30<00:00, 52.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1597 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 302---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1597/1597 [00:30<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1597 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 303---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1597/1597 [00:30<00:00, 52.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1596 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 304---\n",
      "Reading dataframes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596/1596 [00:29<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating dataframes...\n"
     ]
    }
   ],
   "source": [
    "dataframes = list()\n",
    "for d in days: \n",
    "    \n",
    "    print(\"\\n--- \" + str(d) + \"---\")\n",
    "    \n",
    "    # read in the data \n",
    "    df = data.read_day(\n",
    "        location=location,\n",
    "        year=year,\n",
    "        day_of_year=d\n",
    "    )\n",
    "    dataframes.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dataframes loaded previously into one large dataframe \n",
    "df_all = pd.concat(dataframes) \n",
    "df_model = df_all.filter(regex='ahup__G07', axis=1).resample(\"1min\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = np.split(df_model, np.where(np.isnan(df_model))[0])\n",
    "events = [ev[~np.isnan(ev)] for ev in events if not isinstance(ev, np.ndarray)]\n",
    "events = [ev.dropna() for ev in events if not ev.empty and ev.shape[0] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_events = list()\n",
    "for ev in events: \n",
    "\n",
    "    # for each column in the data, rescale -1 to 1 \n",
    "    col_data = list()\n",
    "    for col in ev.columns.values:\n",
    "\n",
    "        normalized_data = minmax_scale(\n",
    "                    ev[col].dropna(), \n",
    "                    feature_range=(-1, 1)\n",
    "                )\n",
    "        col_data.append(normalized_data)\n",
    "\n",
    "    df_period = pd.DataFrame(np.array(col_data).T, columns=list(ev.columns.values) )\n",
    "    df_period[\"timestamp\"] = ev[col].index\n",
    "    df_period.index = df_period[\"timestamp\"]\n",
    "    df_period = df_period.drop(columns=[\"timestamp\"])\n",
    "\n",
    "    # convert to seconds of the day for later annotation \n",
    "    df_period[\"sod\"] = (df_period.index.hour*60+df_period.index.minute)*60 + df_period.index.second\n",
    "\n",
    "    normalized_events.append(df_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "1.076570987701416\n"
     ]
    }
   ],
   "source": [
    "# start the timing here \n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "period = events[0]\n",
    "doy = days[0]\n",
    "idx = 0\n",
    "subset = period.iloc[idx:idx+WINDOW_SIZE, :]\n",
    "\n",
    "# now generate the field \n",
    "transformer = GramianAngularField()\n",
    "X_new = transformer.fit_transform(np.array([subset[\"ahup__G07\"]]))\n",
    "\n",
    "figure = plt.figure(figsize=(5,5), frameon=False)\n",
    "\n",
    "ax = plt.Axes(figure, [0., 0., 1., 1.])\n",
    "ax.set_axis_off()\n",
    "figure.add_axes(ax)\n",
    "\n",
    "figure = plt.imshow(X_new[0], cmap='viridis', origin='lower')\n",
    "\n",
    "x_axis = figure.axes.get_xaxis()\n",
    "x_axis.set_visible(False)\n",
    "\n",
    "y_axis = figure.axes.get_yaxis()\n",
    "y_axis.set_visible(False)\n",
    "\n",
    "plt.savefig(\"../GAF_test.jpg\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# now load the trained model and one particular image and make a prediction \n",
    "learner = load_learner(\"/home/vconstan/projects/sTEC-d-dt-Anomaly-Detection/models/model.pkl\")\n",
    "\n",
    "\n",
    "# load in the image and predict the classification \n",
    "prediction = learner.predict(\"../GAF_test.jpg\")\n",
    "\n",
    "print(prediction[0])\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2 - t1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
